{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from GaussianDiffusion import GaussianDiffusion\n",
    "import imageio\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Values chosen in the paper\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "time_steps = 1000\n",
    "clip_min = -1.0\n",
    "clip_max = 1.0\n",
    "\n",
    "img_size = 64\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the time step functions\n",
    "diffusion_functions = GaussianDiffusion(beta_start=beta_start, beta_end=beta_end, time_steps=time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the model\n",
    "network = tf.keras.models.load_model(\"64pxModelsRandomUniform/Epoch80WithAttention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_images(num_images = 2):\n",
    "    all_samples = []\n",
    "    #Generate the starting point - noisy images\n",
    "    samples = tf.random.normal(shape=(num_images, img_size, img_size, img_channels), dtype = tf.float32)\n",
    "    #Incremental sampling process\n",
    "    for t in reversed(range(0, time_steps)):\n",
    "        #Get time steps of correct shape\n",
    "        tt = tf.cast(tf.fill(num_images, t), dtype = tf.int32)\n",
    "        #Using the time step and samples, predict the noise in the samples\n",
    "        pred_noise = network([samples, tt])\n",
    "        #Get the images from the samples + predicted noise\n",
    "        samples = diffusion_functions.p_sample(pred_noise, samples, tt)\n",
    "        if t %50 == 0:\n",
    "            #print(f\"Time step: {time_steps - t}\")\n",
    "            pass\n",
    "        pass\n",
    "        all_samples.append(samples)\n",
    "    #Clip the image\n",
    "    #samples = tf.clip_by_value(samples, clip_value_min=clip_min, clip_value_max=clip_max)\n",
    "\n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_frames_of_one_image(frames, index):\n",
    "    relevant_frames = []\n",
    "\n",
    "    for step, image in enumerate(frames):\n",
    "        image = image[index]\n",
    "        image = (image + 1)/2\n",
    "        image = image*255\n",
    "        image = np.asarray(image, np.uint8)\n",
    "        if (step+1) < 800:\n",
    "            if (step+1)%20 == 0:\n",
    "                relevant_frames.append(image)\n",
    "                pass\n",
    "            pass\n",
    "        if (step+1) >=800:\n",
    "            if (step+1)%5 == 0:\n",
    "                relevant_frames.append(image)\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return relevant_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_gifs(frames, num_images):\n",
    "    for i in range(num_images):\n",
    "        relevant_frames = get_all_frames_of_one_image(frames, i)\n",
    "        #print(len(relevant_frames))\n",
    "        # Create the GIF using imageio\n",
    "        with imageio.get_writer(f'DenoisingGiFs/diffusionGif{i}.gif', mode='I') as writer:\n",
    "            for image in relevant_frames:\n",
    "                writer.append_data(image)\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "def save_mega_gif(frames, path):\n",
    "    with imageio.get_writer(path, mode='I') as writer:\n",
    "        for image in frames:\n",
    "            writer.append_data(image)\n",
    "            pass\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_images = 16\n",
    "list_batch_frames = generate_images(num_images)\n",
    "save_gifs(frames=list_batch_frames, num_images=num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_frames_mega(list_batch_frames):\n",
    "    batch_size, dim, _, channels = list_batch_frames[0].shape\n",
    "    grid_rows = grid_cols = int(math.sqrt(batch_size))\n",
    "    list_frames = []\n",
    "    for step, batch_frames in enumerate(list_batch_frames):\n",
    "        grid = tf.reshape(batch_frames, (grid_rows, grid_cols, dim, dim, channels))\n",
    "        grid = tf.transpose(grid, (0, 2, 1, 3, 4))\n",
    "        large_image = tf.reshape(grid, (grid_rows * dim, grid_cols * dim, channels))\n",
    "        image = large_image\n",
    "        image = (image + 1)/2\n",
    "        image = image*255\n",
    "        image = np.asarray(image, np.uint8)\n",
    "        if (step+1) < 800:\n",
    "            if (step+1)%20 == 0:\n",
    "                list_frames.append(image)\n",
    "                pass\n",
    "            pass\n",
    "        if (step+1) >=800:\n",
    "            if (step+1)%5 == 0:\n",
    "                list_frames.append(image)\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "        \n",
    "    return list_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted_frames = concatenate_frames_mega(list_batch_frames=list_batch_frames)\n",
    "save_mega_gif(concatted_frames, 'DenoisingGiFs/MegadiffusionGif.gif')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images which were generated by the diffusion model:\n",
    "\n",
    "![GiF](DenoisingGiFs/MegadiffusionGif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
